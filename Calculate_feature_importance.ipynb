{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import Lasso, RidgeClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/lindan/Dropbox/PhD/Projects/PLF/FTIR/Data/JM006_0901_whole.csv')\n",
    "df = df.dropna(subset=['milkweightlbs_sca'])\n",
    "df = df.dropna(subset=['cells'])\n",
    "df_f = df[df['disease'] == 0]\n",
    "# df_d = df[df['disease'] == 1][df['disease_in'] > 14] # 210 \n",
    "# df_d = df[df['disease'] == 1][df['disease_in'] <= 14][df['disease_in'] >= 11] # 94\n",
    "# df_d = df[df['disease'] == 1][df['disease_in'] <= 10][df['disease_in'] >= 8] # 136\n",
    "# df_d = df[df['disease'] == 1][df['disease_in'] <= 7][df['disease_in'] >= 6] # 125\n",
    "# df_d = df[df['disease'] == 1][df['disease_in'] <= 5][df['disease_in'] >= 4] # 199\n",
    "# df_d = df[df['disease'] == 1][df['disease_in'] == 3] # 114\n",
    "# df_d = df[df['disease'] == 1][df['disease_in'] == 2] # 117\n",
    "df_d = df[df['disease'] == 1][df['disease_in'] == 1] # 147\n",
    "df = pd.concat([df_f, df_d])\n",
    "df = df.reset_index(drop=True)\n",
    "X = np.hstack((df.iloc[:,1:488].values, df['milkweightlbs_sca'].values.reshape(-1, 1), df['cells_sca'].values.reshape(-1, 1), df['parity_sca'].values.reshape(-1, 1)))\n",
    "y = df['disease']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLS-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>imp</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002.91</td>\n",
       "      <td>1.402973</td>\n",
       "      <td>PLS-DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.77</td>\n",
       "      <td>1.356892</td>\n",
       "      <td>PLS-DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010.63</td>\n",
       "      <td>1.451879</td>\n",
       "      <td>PLS-DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014.48</td>\n",
       "      <td>1.448652</td>\n",
       "      <td>PLS-DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.34</td>\n",
       "      <td>1.492027</td>\n",
       "      <td>PLS-DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2993.3</td>\n",
       "      <td>0.859332</td>\n",
       "      <td>PLS-DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2997.16</td>\n",
       "      <td>0.941502</td>\n",
       "      <td>PLS-DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>milkweightlbs</td>\n",
       "      <td>2.241255</td>\n",
       "      <td>PLS-DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cells</td>\n",
       "      <td>1.307038</td>\n",
       "      <td>PLS-DA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>parity</td>\n",
       "      <td>0.273815</td>\n",
       "      <td>PLS-DA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable       imp   model\n",
       "0          1002.91  1.402973  PLS-DA\n",
       "1          1006.77  1.356892  PLS-DA\n",
       "2          1010.63  1.451879  PLS-DA\n",
       "3          1014.48  1.448652  PLS-DA\n",
       "4          1018.34  1.492027  PLS-DA\n",
       "..             ...       ...     ...\n",
       "485         2993.3  0.859332  PLS-DA\n",
       "486        2997.16  0.941502  PLS-DA\n",
       "487  milkweightlbs  2.241255  PLS-DA\n",
       "488          cells  1.307038  PLS-DA\n",
       "489         parity  0.273815  PLS-DA\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate Variable Importance in Projection (VIP) in PLS-DA\n",
    "def calculate_vip(model):\n",
    "    t = model.x_scores_\n",
    "    w = model.x_weights_\n",
    "    q = model.y_loadings_\n",
    "    p, h = w.shape\n",
    "    vips = np.zeros((p,))\n",
    "    s = np.diag(np.matmul(np.matmul(np.matmul(t.T,t),q.T), q)).reshape(h, -1)\n",
    "    total_s = np.sum(s)\n",
    "    for i in range(p):\n",
    "        weight = np.array([ (w[i,j] / np.linalg.norm(w[:,j]))**2 for j in range(h) ])\n",
    "        vips[i] = np.sqrt(p*(np.matmul(s.T, weight))/total_s)\n",
    "    return vips\n",
    "\n",
    "# Construct feature importance dataframe\n",
    "imp = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "# Down samping\n",
    "X_0 = X[y == 0]\n",
    "X_1 = X[y == 1]\n",
    "n_samples = 50 \n",
    "\n",
    "for i in range(n_samples):\n",
    "    sampled_indices = np.random.choice(len(X_0), size=len(X_1), replace=True)\n",
    "    X_0_sampled = X_0[sampled_indices]\n",
    "    X_sampled = np.vstack((X_0_sampled, X_1))\n",
    "    y_sampled = np.array([0] * len(X_0_sampled) + [1] * len(X_1))\n",
    "    \n",
    "    # Fit PLS-DA\n",
    "    model = PLSRegression(n_components=2)\n",
    "    model.fit(X_sampled, y_sampled)\n",
    "\n",
    "    # Calculate VIP\n",
    "    VIP = calculate_vip(model)\n",
    "    i = i + 1\n",
    "    imp[f'Fea_{i}'] = VIP\n",
    "\n",
    "imp_pls_da = pd.DataFrame({\n",
    "    'variable': df.iloc[:,1:488].columns.tolist() + ['milkweightlbs'] + ['cells'] + ['parity'],\n",
    "    'imp': imp.mean(axis=1),\n",
    "    'model': 'PLS-DA'\n",
    "})\n",
    "imp_pls_da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>imp</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002.91</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.77</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010.63</td>\n",
       "      <td>0.004821</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014.48</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2993.3</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2997.16</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>milkweightlbs</td>\n",
       "      <td>1.032065</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cells</td>\n",
       "      <td>0.429457</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>parity</td>\n",
       "      <td>0.419281</td>\n",
       "      <td>Lasso</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable       imp  model\n",
       "0          1002.91  0.000000  Lasso\n",
       "1          1006.77  0.003193  Lasso\n",
       "2          1010.63  0.004821  Lasso\n",
       "3          1014.48  0.000000  Lasso\n",
       "4          1018.34  0.000000  Lasso\n",
       "..             ...       ...    ...\n",
       "485         2993.3  0.003509  Lasso\n",
       "486        2997.16  0.001532  Lasso\n",
       "487  milkweightlbs  1.032065  Lasso\n",
       "488          cells  0.429457  Lasso\n",
       "489         parity  0.419281  Lasso\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct feature importance dataframe\n",
    "imp = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "# Down samping\n",
    "X_0 = X[y == 0]\n",
    "X_1 = X[y == 1]\n",
    "n_samples = 50 \n",
    "\n",
    "for i in range(n_samples):\n",
    "    sampled_indices = np.random.choice(len(X_0), size=len(X_1), replace=True)\n",
    "    X_0_sampled = X_0[sampled_indices]\n",
    "    X_sampled = np.vstack((X_0_sampled, X_1))\n",
    "    y_sampled = np.array([0] * len(X_0_sampled) + [1] * len(X_1))\n",
    "    \n",
    "    # Fit Lasso\n",
    "    model = LogisticRegression(penalty='l1', solver='saga', C=1.0)\n",
    "    model.fit(X_sampled, y_sampled)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    coefficients = model.coef_[0]\n",
    "    coefficients = coefficients.flatten().tolist()\n",
    "    i = i + 1\n",
    "    imp[f'Fea_{i}'] = coefficients\n",
    "\n",
    "imp_lasso = pd.DataFrame({\n",
    "    'variable': df.iloc[:,1:488].columns.tolist() + ['milkweightlbs'] + ['cells'] + ['parity'],\n",
    "    'imp': imp.mean(axis=1), \n",
    "    'model': 'Lasso'\n",
    "})\n",
    "imp_lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>imp</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002.91</td>\n",
       "      <td>0.052654</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.77</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010.63</td>\n",
       "      <td>0.036501</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014.48</td>\n",
       "      <td>0.017925</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.34</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2993.3</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2997.16</td>\n",
       "      <td>0.090833</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>milkweightlbs</td>\n",
       "      <td>0.355259</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cells</td>\n",
       "      <td>0.063060</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>parity</td>\n",
       "      <td>0.134548</td>\n",
       "      <td>Ridge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable       imp  model\n",
       "0          1002.91  0.052654  Ridge\n",
       "1          1006.77  0.002649  Ridge\n",
       "2          1010.63  0.036501  Ridge\n",
       "3          1014.48  0.017925  Ridge\n",
       "4          1018.34  0.011952  Ridge\n",
       "..             ...       ...    ...\n",
       "485         2993.3  0.008757  Ridge\n",
       "486        2997.16  0.090833  Ridge\n",
       "487  milkweightlbs  0.355259  Ridge\n",
       "488          cells  0.063060  Ridge\n",
       "489         parity  0.134548  Ridge\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct feature importance dataframe\n",
    "imp = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "# Down samping\n",
    "X_0 = X[y == 0]\n",
    "X_1 = X[y == 1]\n",
    "n_samples = 50 \n",
    "\n",
    "for i in range(n_samples):\n",
    "    sampled_indices = np.random.choice(len(X_0), size=len(X_1), replace=True)\n",
    "    X_0_sampled = X_0[sampled_indices]\n",
    "    X_sampled = np.vstack((X_0_sampled, X_1))\n",
    "    y_sampled = np.array([0] * len(X_0_sampled) + [1] * len(X_1))\n",
    "    \n",
    "    # Fit Ridge\n",
    "    model = RidgeClassifier()\n",
    "    model.fit(X_sampled, y_sampled)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    coefficients = model.coef_[0]\n",
    "    coefficients = coefficients.flatten().tolist()\n",
    "    i = i + 1\n",
    "    imp[f'Fea_{i}'] = coefficients\n",
    "\n",
    "imp_Ridge = pd.DataFrame({\n",
    "    'variable': df.iloc[:,1:488].columns.tolist() + ['milkweightlbs'] + ['cells'] + ['parity'],\n",
    "    'imp': imp.mean(axis=1),\n",
    "    'model': 'Ridge'\n",
    "})\n",
    "imp_Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "The max_iter was reached which means the coef_ did not converge\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>imp</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002.91</td>\n",
       "      <td>6.877237e-04</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.77</td>\n",
       "      <td>6.846354e-03</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010.63</td>\n",
       "      <td>9.510051e-03</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014.48</td>\n",
       "      <td>8.185471e-04</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.34</td>\n",
       "      <td>1.690693e-09</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2993.3</td>\n",
       "      <td>8.052354e-03</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2997.16</td>\n",
       "      <td>1.225271e-02</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>milkweightlbs</td>\n",
       "      <td>1.014428e+00</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cells</td>\n",
       "      <td>3.961107e-01</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>parity</td>\n",
       "      <td>4.352728e-01</td>\n",
       "      <td>EN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable           imp model\n",
       "0          1002.91  6.877237e-04    EN\n",
       "1          1006.77  6.846354e-03    EN\n",
       "2          1010.63  9.510051e-03    EN\n",
       "3          1014.48  8.185471e-04    EN\n",
       "4          1018.34  1.690693e-09    EN\n",
       "..             ...           ...   ...\n",
       "485         2993.3  8.052354e-03    EN\n",
       "486        2997.16  1.225271e-02    EN\n",
       "487  milkweightlbs  1.014428e+00    EN\n",
       "488          cells  3.961107e-01    EN\n",
       "489         parity  4.352728e-01    EN\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct feature importance dataframe\n",
    "imp = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "# Down samping\n",
    "X_0 = X[y == 0]\n",
    "X_1 = X[y == 1]\n",
    "n_samples = 50 \n",
    "\n",
    "for i in range(n_samples):\n",
    "    sampled_indices = np.random.choice(len(X_0), size=len(X_1), replace=True)\n",
    "    X_0_sampled = X_0[sampled_indices]\n",
    "    X_sampled = np.vstack((X_0_sampled, X_1))\n",
    "    y_sampled = np.array([0] * len(X_0_sampled) + [1] * len(X_1))\n",
    "    \n",
    "    # Fit EN\n",
    "    model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5)\n",
    "    model.fit(X_sampled, y_sampled)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    coefficients = model.coef_[0]\n",
    "    coefficients = coefficients.flatten().tolist()\n",
    "    i = i + 1\n",
    "    imp[f'Fea_{i}'] = coefficients\n",
    "\n",
    "imp_Elastic_Net = pd.DataFrame({\n",
    "    'variable': df.iloc[:,1:488].columns.tolist() + ['milkweightlbs'] + ['cells'] + ['parity'],\n",
    "    'imp': imp.mean(axis=1),\n",
    "    'model': 'EN'\n",
    "})\n",
    "imp_Elastic_Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>imp</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002.91</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.77</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010.63</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014.48</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.34</td>\n",
       "      <td>0.003670</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2993.3</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2997.16</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>milkweightlbs</td>\n",
       "      <td>0.011055</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cells</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>parity</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable       imp model\n",
       "0          1002.91  0.003100    RF\n",
       "1          1006.77  0.002860    RF\n",
       "2          1010.63  0.001704    RF\n",
       "3          1014.48  0.001903    RF\n",
       "4          1018.34  0.003670    RF\n",
       "..             ...       ...   ...\n",
       "485         2993.3  0.001007    RF\n",
       "486        2997.16  0.000402    RF\n",
       "487  milkweightlbs  0.011055    RF\n",
       "488          cells  0.006357    RF\n",
       "489         parity  0.001990    RF\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct feature importance dataframe\n",
    "imp = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "# Down samping\n",
    "X_0 = X[y == 0]\n",
    "X_1 = X[y == 1]\n",
    "n_samples = 50 \n",
    "\n",
    "for i in range(n_samples):\n",
    "    sampled_indices = np.random.choice(len(X_0), size=len(X_1), replace=True)\n",
    "    X_0_sampled = X_0[sampled_indices]\n",
    "    X_sampled = np.vstack((X_0_sampled, X_1))\n",
    "    y_sampled = np.array([0] * len(X_0_sampled) + [1] * len(X_1))\n",
    "    \n",
    "    # Fit RF\n",
    "    model = RandomForestClassifier(max_depth=2, n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    model.fit(X_sampled, y_sampled)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    feature_importances = model.feature_importances_\n",
    "    coefficients = feature_importances.flatten().tolist()\n",
    "    i = i + 1\n",
    "    imp[f'Fea_{i}'] = coefficients\n",
    "\n",
    "imp_RF = pd.DataFrame({\n",
    "    'variable': df.iloc[:,1:488].columns.tolist() + ['milkweightlbs'] + ['cells'] + ['parity'],\n",
    "    'imp': imp.mean(axis=1),\n",
    "    'model': 'RF'\n",
    "})\n",
    "imp_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>imp</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002.91</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.77</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010.63</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014.48</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.34</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2993.3</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2997.16</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>milkweightlbs</td>\n",
       "      <td>0.012999</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cells</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>parity</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable       imp    model\n",
       "0          1002.91  0.001850  XGBoost\n",
       "1          1006.77  0.001615  XGBoost\n",
       "2          1010.63  0.004022  XGBoost\n",
       "3          1014.48  0.001579  XGBoost\n",
       "4          1018.34  0.003065  XGBoost\n",
       "..             ...       ...      ...\n",
       "485         2993.3  0.001602  XGBoost\n",
       "486        2997.16  0.003005  XGBoost\n",
       "487  milkweightlbs  0.012999  XGBoost\n",
       "488          cells  0.013095  XGBoost\n",
       "489         parity  0.004183  XGBoost\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct feature importance dataframe\n",
    "imp = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "# Down samping\n",
    "X_0 = X[y == 0]\n",
    "X_1 = X[y == 1]\n",
    "n_samples = 50 \n",
    "\n",
    "for i in range(n_samples):\n",
    "    sampled_indices = np.random.choice(len(X_0), size=len(X_1), replace=True)\n",
    "    X_0_sampled = X_0[sampled_indices]\n",
    "    X_sampled = np.vstack((X_0_sampled, X_1))\n",
    "    y_sampled = np.array([0] * len(X_0_sampled) + [1] * len(X_1))\n",
    "    \n",
    "    # Fit XGBoost\n",
    "    model = XGBClassifier(max_depth=2, n_estimators=100, use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_sampled, y_sampled)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    feature_importances = model.feature_importances_\n",
    "    coefficients = feature_importances.flatten().tolist()\n",
    "    i = i + 1\n",
    "    imp[f'Fea_{i}'] = coefficients\n",
    "\n",
    "imp_XGBoost = pd.DataFrame({\n",
    "    'variable': df.iloc[:,1:488].columns.tolist() + ['milkweightlbs'] + ['cells'] + ['parity'],\n",
    "    'imp': imp.mean(axis=1),\n",
    "    'model': 'XGBoost'\n",
    "})\n",
    "imp_XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class MLPClassifierCustom(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_shape, hidden_layer_sizes=(100,), activation='relu', epochs=200, batch_size=32):\n",
    "        self.input_shape = input_shape  \n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.activation = activation\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.hidden_layer_sizes[0], activation=self.activation, input_shape=(self.input_shape,)))\n",
    "        \n",
    "        for layer_size in self.hidden_layer_sizes[1:]:\n",
    "            model.add(Dense(layer_size, activation=self.activation))\n",
    "            \n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        return (y_pred > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>imp</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002.91</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.77</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010.63</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014.48</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.34</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2993.3</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2997.16</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>milkweightlbs</td>\n",
       "      <td>0.093873</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cells</td>\n",
       "      <td>0.044710</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>parity</td>\n",
       "      <td>0.027157</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable       imp model\n",
       "0          1002.91  0.002659   MLP\n",
       "1          1006.77  0.002047   MLP\n",
       "2          1010.63  0.002325   MLP\n",
       "3          1014.48  0.001539   MLP\n",
       "4          1018.34  0.002655   MLP\n",
       "..             ...       ...   ...\n",
       "485         2993.3  0.000877   MLP\n",
       "486        2997.16  0.001136   MLP\n",
       "487  milkweightlbs  0.093873   MLP\n",
       "488          cells  0.044710   MLP\n",
       "489         parity  0.027157   MLP\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct feature importance dataframe\n",
    "imp = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "# Down samping\n",
    "X_0 = X[y == 0]\n",
    "X_1 = X[y == 1]\n",
    "n_samples = 50 \n",
    "\n",
    "for i in range(n_samples):\n",
    "    sampled_indices = np.random.choice(len(X_0), size=len(X_1), replace=True)\n",
    "    X_0_sampled = X_0[sampled_indices]\n",
    "    X_sampled = np.vstack((X_0_sampled, X_1))\n",
    "    y_sampled = np.array([0] * len(X_0_sampled) + [1] * len(X_1))\n",
    "\n",
    "    # Fit ANN\n",
    "    model = MLPClassifierCustom(input_shape=X.shape[1], hidden_layer_sizes=(32, 128, 32)) \n",
    "    model.fit(X_sampled, y_sampled)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    explainer = shap.GradientExplainer(model.model, [X_sampled, y_sampled])\n",
    "    shap_values = explainer.shap_values(X_sampled)  \n",
    "    shap_values = np.array(shap_values)\n",
    "    shap_values = shap_values.reshape(X_sampled.shape[0], X_sampled.shape[1])\n",
    "    shap_values = [abs(x) for x in np.mean(abs(shap_values), axis=0)]\n",
    "    i = i + 1\n",
    "    imp[f'Fea_{i}'] = shap_values\n",
    "\n",
    "imp_ANN = pd.DataFrame({\n",
    "    'variable': df.iloc[:,1:488].columns.tolist() + ['milkweightlbs'] + ['cells'] + ['parity'],\n",
    "    'imp': imp.mean(axis=1),\n",
    "    'model': 'MLP'\n",
    "})\n",
    "imp_ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class CNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_shape, epochs=200, batch_size=32):\n",
    "        self.input_shape = input_shape  \n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(8, kernel_size=3, activation='relu', input_shape=self.input_shape)) # 16\n",
    "        model.add(Conv1D(12, kernel_size=3, activation='relu')) \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(16, activation='relu')) # 16\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        return (y_pred > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>imp</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002.91</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.77</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010.63</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014.48</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.34</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2993.3</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2997.16</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>milkweightlbs</td>\n",
       "      <td>0.100885</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cells</td>\n",
       "      <td>0.035565</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>parity</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable       imp model\n",
       "0          1002.91  0.000886   CNN\n",
       "1          1006.77  0.001341   CNN\n",
       "2          1010.63  0.001762   CNN\n",
       "3          1014.48  0.001902   CNN\n",
       "4          1018.34  0.001783   CNN\n",
       "..             ...       ...   ...\n",
       "485         2993.3  0.001529   CNN\n",
       "486        2997.16  0.001480   CNN\n",
       "487  milkweightlbs  0.100885   CNN\n",
       "488          cells  0.035565   CNN\n",
       "489         parity  0.012500   CNN\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct feature importance dataframe\n",
    "imp = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "# Down samping\n",
    "X_cnn = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "X_0 = X_cnn[y == 0]\n",
    "X_1 = X_cnn[y == 1]\n",
    "n_samples = 50 \n",
    "\n",
    "for i in range(n_samples):\n",
    "    sampled_indices = np.random.choice(len(X_0), size=len(X_1), replace=True)\n",
    "    X_0_sampled = X_0[sampled_indices]\n",
    "    X_sampled = np.vstack((X_0_sampled, X_1))\n",
    "    y_sampled = np.array([0] * len(X_0_sampled) + [1] * len(X_1))\n",
    "    \n",
    "    # Fit CNN\n",
    "    model = CNNClassifier(input_shape=(X_cnn.shape[1], 1))\n",
    "    model.fit(X_sampled, y_sampled)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    explainer = shap.GradientExplainer(model.model, [X_sampled, y_sampled])\n",
    "    shap_values = explainer.shap_values(X_sampled)  \n",
    "    shap_values = np.array(shap_values)\n",
    "    shap_values = shap_values.reshape(X_sampled.shape[0], X_sampled.shape[1])\n",
    "    shap_values = [abs(x) for x in np.mean(abs(shap_values), axis=0)]\n",
    "    i = i + 1\n",
    "    imp[f'Fea_{i}'] = shap_values\n",
    "\n",
    "imp_CNN = pd.DataFrame({\n",
    "    'variable': df.iloc[:,1:488].columns.tolist() + ['milkweightlbs'] + ['cells'] + ['parity'],\n",
    "    'imp': imp.mean(axis=1),\n",
    "    'model': 'CNN'\n",
    "})\n",
    "imp_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, MaxPooling1D\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class LSTMClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_shape, units=20, epochs=200, batch_size=32):\n",
    "        self.input_shape = input_shape  \n",
    "        self.units = units \n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(self.units, activation='relu', input_shape=self.input_shape))\n",
    "        model.add(Dense(64, activation='relu')) # 64\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        return (y_pred > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>imp</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002.91</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.77</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010.63</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014.48</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.34</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2993.3</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2997.16</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>milkweightlbs</td>\n",
       "      <td>0.127211</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cells</td>\n",
       "      <td>0.059509</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>parity</td>\n",
       "      <td>0.058768</td>\n",
       "      <td>LSTM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable       imp model\n",
       "0          1002.91  0.001651  LSTM\n",
       "1          1006.77  0.000897  LSTM\n",
       "2          1010.63  0.001881  LSTM\n",
       "3          1014.48  0.000945  LSTM\n",
       "4          1018.34  0.001571  LSTM\n",
       "..             ...       ...   ...\n",
       "485         2993.3  0.000607  LSTM\n",
       "486        2997.16  0.001872  LSTM\n",
       "487  milkweightlbs  0.127211  LSTM\n",
       "488          cells  0.059509  LSTM\n",
       "489         parity  0.058768  LSTM\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct feature importance dataframe\n",
    "imp = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "# Down samping\n",
    "X_lstm = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "X_0 = X_lstm[y == 0]\n",
    "X_1 = X_lstm[y == 1]\n",
    "n_samples = 5 \n",
    "\n",
    "for i in range(n_samples):\n",
    "    sampled_indices = np.random.choice(len(X_0), size=len(X_1), replace=True)\n",
    "    X_0_sampled = X_0[sampled_indices]\n",
    "    X_sampled = np.vstack((X_0_sampled, X_1))\n",
    "    y_sampled = np.array([0] * len(X_0_sampled) + [1] * len(X_1))\n",
    "    \n",
    "    # Fit LSTM\n",
    "    model = LSTMClassifier(input_shape=(1, X_lstm.shape[2]), units=20, epochs=200, batch_size=32)\n",
    "    model.fit(X_sampled, y_sampled)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    explainer = shap.GradientExplainer(model.model, [X_sampled, y_sampled])\n",
    "    shap_values = explainer.shap_values(X_sampled)  \n",
    "    shap_values = np.array(shap_values)\n",
    "    shap_values = shap_values.reshape(X_sampled.shape[0], X_sampled.shape[2])\n",
    "    shap_values = [abs(x) for x in np.mean(abs(shap_values), axis=0)]\n",
    "    i = i + 1\n",
    "    imp[f'Fea_{i}'] = shap_values\n",
    "\n",
    "imp_LSTM = pd.DataFrame({\n",
    "    'variable': df.iloc[:,1:488].columns.tolist() + ['milkweightlbs'] + ['cells'] + ['parity'],\n",
    "    'imp': imp.mean(axis=1),\n",
    "    'model': 'LSTM'\n",
    "})\n",
    "imp_LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "class GRUClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, input_shape, units=20, epochs=200, batch_size=32):\n",
    "        self.input_shape = input_shape  \n",
    "        self.units = units  \n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model = self._build_model()\n",
    "        \n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(GRU(self.units, activation='relu', input_shape=self.input_shape))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.model.predict(X)\n",
    "        return (y_pred > 0.5).astype(int).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>imp</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002.91</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006.77</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010.63</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014.48</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1018.34</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2993.3</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2997.16</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>milkweightlbs</td>\n",
       "      <td>0.117175</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>cells</td>\n",
       "      <td>0.051612</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>parity</td>\n",
       "      <td>0.035012</td>\n",
       "      <td>GRU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          variable       imp model\n",
       "0          1002.91  0.003386   GRU\n",
       "1          1006.77  0.002044   GRU\n",
       "2          1010.63  0.002614   GRU\n",
       "3          1014.48  0.001548   GRU\n",
       "4          1018.34  0.001523   GRU\n",
       "..             ...       ...   ...\n",
       "485         2993.3  0.001312   GRU\n",
       "486        2997.16  0.001361   GRU\n",
       "487  milkweightlbs  0.117175   GRU\n",
       "488          cells  0.051612   GRU\n",
       "489         parity  0.035012   GRU\n",
       "\n",
       "[490 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct feature importance dataframe\n",
    "imp = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "# Down samping\n",
    "X_gru = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "X_0 = X_gru[y == 0]\n",
    "X_1 = X_gru[y == 1]\n",
    "n_samples = 5 \n",
    "\n",
    "for i in range(n_samples):\n",
    "    sampled_indices = np.random.choice(len(X_0), size=len(X_1), replace=True)\n",
    "    X_0_sampled = X_0[sampled_indices]\n",
    "    X_sampled = np.vstack((X_0_sampled, X_1))\n",
    "    y_sampled = np.array([0] * len(X_0_sampled) + [1] * len(X_1))\n",
    "    \n",
    "    # Fit GRU\n",
    "    model = GRUClassifier(input_shape=(1, X_gru.shape[2]), units=20, epochs=200, batch_size=32)\n",
    "    model.fit(X_sampled, y_sampled)\n",
    "\n",
    "    # Calculate feature importance\n",
    "    explainer = shap.GradientExplainer(model.model, [X_sampled, y_sampled])\n",
    "    shap_values = explainer.shap_values(X_sampled)  \n",
    "    shap_values = np.array(shap_values)\n",
    "    shap_values = shap_values.reshape(X_sampled.shape[0], X_sampled.shape[2])\n",
    "    shap_values = [abs(x) for x in np.mean(abs(shap_values), axis=0)]\n",
    "    i = i + 1\n",
    "    imp[f'Fea_{i}'] = shap_values\n",
    "\n",
    "imp_GRU = pd.DataFrame({\n",
    "    'variable': df.iloc[:,1:488].columns.tolist() + ['milkweightlbs'] + ['cells'] +  ['parity'],\n",
    "    'imp': imp.mean(axis=1),\n",
    "    'model': 'GRU'\n",
    "})\n",
    "imp_GRU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
